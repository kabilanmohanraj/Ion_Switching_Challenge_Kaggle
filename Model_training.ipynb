{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Batchwise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q88UIyzMqS34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Activation, LSTM, BatchNormalization, TimeDistributed, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKM7u1bGJY61",
        "colab_type": "code",
        "outputId": "9101144d-2288-477e-e8fe-04c2991c4710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c9pBTVfiTGL",
        "colab_type": "code",
        "outputId": "52266974-9352-4115-a8b9-bb2128ad0726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/train_clean.csv')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/test_clean.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>signal</th>\n",
              "      <th>open_channels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>-2.7600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0002</td>\n",
              "      <td>-2.8557</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0003</td>\n",
              "      <td>-2.4074</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0004</td>\n",
              "      <td>-3.1404</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0005</td>\n",
              "      <td>-3.1525</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     time  signal  open_channels\n",
              "0  0.0001 -2.7600              0\n",
              "1  0.0002 -2.8557              0\n",
              "2  0.0003 -2.4074              0\n",
              "3  0.0004 -3.1404              0\n",
              "4  0.0005 -3.1525              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25gbrtTWPZ4N",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLOsxZEDPXq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5 models created -- 1s, 1f, 3, 5, 10\n",
        "\n",
        "# upto 1 cahnnel open (low channel open probability)\n",
        "rf1s = RandomForestClassifier(n_estimators=1000, max_depth=1)\n",
        "\n",
        "# upto 1 cahnnel open (high channel open probability)\n",
        "rf1f = RandomForestClassifier(n_estimators=1000, max_depth=1)\n",
        "\n",
        "# upto 3 cahnnels open\n",
        "rf3 = RandomForestClassifier(n_estimators=1000, max_leaf_nodes=4)\n",
        "\n",
        "# upto 5 cahnnels open\n",
        "rf5 = RandomForestClassifier(n_estimators=1000, max_leaf_nodes=6)\n",
        "\n",
        "# upto 10 cahnnels open\n",
        "rf10 = RandomForestClassifier(n_estimators=1000, max_leaf_nodes=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwyKBNBlGs-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "resample = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='not majority'), random_state=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGXUjk7WvZEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = resample.fit_sample(np.array(train_df['signal'][0:1000000]).reshape(-1, 1), np.array(train_df['open_channels'][0:1000000]).reshape(-1, 1))\n",
        "rf1s.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nc8YP9fwxoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf1f_X = np.concatenate([train_df['signal'].values[1000000: 1500000], train_df['signal'].values[3000000: 3500000]])\n",
        "rf1f_y = np.concatenate([train_df['open_channels'].values[1000000: 1500000], train_df['open_channels'].values[3000000: 3500000]])\n",
        "\n",
        "X, y = resample.fit_sample(np.array(rf1f_X).reshape(-1, 1), np.array(rf1f_y).reshape(-1, 1))\n",
        "rf1f.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COs8yg3cyIff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf3_X = np.concatenate([train_df['signal'].values[1500000: 2000000], train_df['signal'].values[3500000: 4000000]])\n",
        "rf3_y = np.concatenate([train_df['open_channels'].values[1500000: 2000000], train_df['open_channels'].values[3500000: 4000000]])\n",
        "\n",
        "X, y = resample.fit_sample(np.array(rf3_X).reshape(-1, 1), np.array(rf3_y).reshape(-1, 1))\n",
        "rf3.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlEQx81G0jIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf5_X = np.concatenate([train_df['signal'].values[2500000: 3000000], train_df['signal'].values[4000000: 4500000]])\n",
        "rf5_y = np.concatenate([train_df['open_channels'].values[2500000: 3000000], train_df['open_channels'].values[4000000: 4500000]])\n",
        "\n",
        "X, y = resample.fit_sample(np.array(rf5_X).reshape(-1, 1), np.array(rf5_y).reshape(-1, 1))\n",
        "rf5.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTIht9RW1B_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf10_y = np.concatenate([train_df['open_channels'].values[2000000: 2500000], train_df['open_channels'].values[4500000: 5000000]])\n",
        "rf10_y = pd.Series(rf10_y)\n",
        "index =np.array([rf10_y[rf10_y == 0].index[0], rf10_y[rf10_y == 0].index[1]])\n",
        "\n",
        "rf10_X = np.concatenate([train_df['signal'].values[2000000: 2500000], train_df['signal'].values[4500000: 5000000]])\n",
        "rf10_y = np.concatenate([train_df['open_channels'].values[2000000: 2500000], train_df['open_channels'].values[4500000: 5000000]])\n",
        "rf10_X = np.delete(rf10_X, index)\n",
        "rf10_y = np.delete(rf10_y, index)\n",
        "resample = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='not majority', n_neighbors=2), random_state=100)\n",
        "X, y = resample.fit_sample(np.array(rf10_X).reshape(-1, 1), np.array(rf10_y).reshape(-1, 1))\n",
        "rf10.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDH0Pkgg2tNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicitons\n",
        "sub = pd.read_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/sample_submission.csv')\n",
        "\n",
        "a = 0 # SUBSAMPLE A, Model 1s\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf1s.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 1 # SUBSAMPLE B, Model 3\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf3.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 2 # SUBSAMPLE C, Model 5\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf5.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 3 # SUBSAMPLE D, Model 1s\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf1s.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 4 # SUBSAMPLE E, Model 1f\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf1f.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 5 # SUBSAMPLE F, Model 10\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf10.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 6 # SUBSAMPLE G, Model 5\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf5.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 7 # SUBSAMPLE H, Model 10\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf10.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 8 # SUBSAMPLE I, Model 1s\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf1s.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        "a = 9 # SUBSAMPLE J, Model 3\n",
        "sub.iloc[100000*a:100000*(a+1),1] = rf3.predict(test_df['signal'].values[100000*a:100000*(a+1)].reshape((-1,1)))\n",
        "\n",
        " # BATCHES 3 AND 4, Model 1s\n",
        "sub.iloc[1000000:2000000,1] = rf1s.predict(test_df['signal'].values[1000000:2000000].reshape((-1,1)))\n",
        "\n",
        "sub.to_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/submission-Random-Forest.csv',index=False,float_format='%.4f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcHV_pLFS4uR",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV7k9E7LS97O",
        "colab_type": "code",
        "outputId": "408f50b9-8d50-44d1-96b5-b2f578dacc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "def step_decay(epoch):\n",
        "    # Learning rate scheduler object\n",
        "    initial_lrate = 0.1\n",
        "    drop = 0.001\n",
        "    epochs_drop = 3.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "\n",
        "\n",
        "# Model 1s\n",
        "maxchannels = 1\n",
        "model1s = Sequential()\n",
        "timestep = 1\n",
        "input_dim = 1\n",
        "model1s.add(TimeDistributed(Conv1D(filters=128, kernel_size=1, activation='relu'), input_shape=(None, 1, 1)))\n",
        "model1s.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model1s.add(TimeDistributed(Flatten()))\n",
        "model1s.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model1s.add(BatchNormalization())\n",
        "model1s.add(Dropout(0.2))\n",
        "model1s.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model1s.add(BatchNormalization())\n",
        "model1s.add(Dropout(0.2))\n",
        "model1s.add(LSTM(256, activation='relu'))\n",
        "model1s.add(BatchNormalization())\n",
        "model1s.add(Dropout(0.2))\n",
        "model1s.add(Dense(maxchannels+1))\n",
        "model1s.add(Activation('softmax'))\n",
        "\n",
        "# Model 1f\n",
        "maxchannels = 1\n",
        "model1f = Sequential()\n",
        "timestep = 1\n",
        "input_dim = 1\n",
        "model1f.add(TimeDistributed(Conv1D(filters=128, kernel_size=1, activation='relu'), input_shape=(None, 1, 1)))\n",
        "model1f.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model1f.add(TimeDistributed(Flatten()))\n",
        "model1f.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model1f.add(BatchNormalization())\n",
        "model1f.add(Dropout(0.2))\n",
        "model1f.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model1f.add(BatchNormalization())\n",
        "model1f.add(Dropout(0.2))\n",
        "model1f.add(LSTM(256, activation='relu'))\n",
        "model1f.add(BatchNormalization())\n",
        "model1f.add(Dropout(0.2))\n",
        "model1f.add(Dense(maxchannels+1))\n",
        "model1f.add(Activation('softmax'))\n",
        "model1f.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=11, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "# Model 3\n",
        "maxchannels = 3\n",
        "model3 = Sequential()\n",
        "timestep = 1\n",
        "input_dim = 1\n",
        "model3.add(TimeDistributed(Conv1D(filters=128, kernel_size=1, activation='relu'), input_shape=(None, 1, 1)))\n",
        "model3.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model3.add(TimeDistributed(Flatten()))\n",
        "model3.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(LSTM(256, activation='relu'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(maxchannels+1))\n",
        "model3.add(Activation('softmax'))\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=11, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "# Model 5\n",
        "maxchannels = 5\n",
        "model5 = Sequential()\n",
        "timestep = 1\n",
        "input_dim = 1\n",
        "model5.add(TimeDistributed(Conv1D(filters=128, kernel_size=1, activation='relu'), input_shape=(None, 1, 1)))\n",
        "model5.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model5.add(TimeDistributed(Flatten()))\n",
        "model5.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(LSTM(256, activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(Dense(maxchannels+1))\n",
        "model5.add(Activation('softmax'))\n",
        "model5.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=11, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "# Model 10\n",
        "maxchannels = 10\n",
        "model10 = Sequential()\n",
        "timestep = 1\n",
        "input_dim = 1\n",
        "model10.add(TimeDistributed(Conv1D(filters=128, kernel_size=1, activation='relu'), input_shape=(None, 1, 1)))\n",
        "model10.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model10.add(TimeDistributed(Flatten()))\n",
        "model10.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model10.add(BatchNormalization())\n",
        "model10.add(Dropout(0.2))\n",
        "model10.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model10.add(BatchNormalization())\n",
        "model10.add(Dropout(0.2))\n",
        "model10.add(LSTM(256, activation='relu'))\n",
        "model10.add(BatchNormalization())\n",
        "model10.add(Dropout(0.2))\n",
        "model10.add(Dense(maxchannels))\n",
        "model10.add(Activation('softmax'))\n",
        "model10.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=11, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN-Apw0aXmH_",
        "colab_type": "text"
      },
      "source": [
        "### Batchwise resampling and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpCPbuoDXkYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "resample = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='not majority'), random_state=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_LX7nmHQNXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ_CrGTyX6Yh",
        "colab_type": "code",
        "outputId": "2c658940-b3e7-466a-9e01-7954f2269591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "X, y = resample.fit_sample(np.array(train_df['signal'][0:1000000]).reshape(-1, 1), np.array(train_df['open_channels'][0:1000000]).reshape(-1, 1))\n",
        "\n",
        "a = pd.DataFrame(X, columns=['signal'])\n",
        "a = a.to_numpy()\n",
        "X = a.reshape(X.shape[0], 1, 1, 1)\n",
        "\n",
        "b = pd.DataFrame(y, columns=['open_channels'])\n",
        "b = b.to_numpy()\n",
        "y = b.reshape(len(b), 1)\n",
        "from numpy import array\n",
        "y = to_categorical(array(y), num_classes=2)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=100)\n",
        "\n",
        "model1s.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=2, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "model1s.fit(x=X_train, y=y_train, initial_epoch=0, epochs=4, batch_size=256, callbacks=[lrate], verbose=1, shuffle=False, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "6745/6745 [==============================] - 100s 15ms/step - loss: 0.0180 - accuracy: 0.9939 - precision_24: 0.9939 - recall_24: 0.9939 - f1_score: 0.9939 - val_loss: 0.0130 - val_accuracy: 0.9952 - val_precision_24: 0.9952 - val_recall_24: 0.9952 - val_f1_score: 0.9952 - lr: 0.1000\n",
            "Epoch 2/4\n",
            "6745/6745 [==============================] - 100s 15ms/step - loss: 0.0146 - accuracy: 0.9948 - precision_24: 0.9948 - recall_24: 0.9948 - f1_score: 0.9948 - val_loss: 0.0131 - val_accuracy: 0.9952 - val_precision_24: 0.9952 - val_recall_24: 0.9952 - val_f1_score: 0.9952 - lr: 0.1000\n",
            "Epoch 3/4\n",
            "6745/6745 [==============================] - 101s 15ms/step - loss: 0.0144 - accuracy: 0.9951 - precision_24: 0.9951 - recall_24: 0.9951 - f1_score: 0.9951 - val_loss: 0.0127 - val_accuracy: 0.9954 - val_precision_24: 0.9954 - val_recall_24: 0.9954 - val_f1_score: 0.9954 - lr: 1.0000e-04\n",
            "Epoch 4/4\n",
            "6745/6745 [==============================] - 100s 15ms/step - loss: 0.0138 - accuracy: 0.9951 - precision_24: 0.9951 - recall_24: 0.9951 - f1_score: 0.9951 - val_loss: 0.0126 - val_accuracy: 0.9953 - val_precision_24: 0.9953 - val_recall_24: 0.9953 - val_f1_score: 0.9953 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c528fe748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OhCgU26S8e5",
        "colab_type": "code",
        "outputId": "17c272d5-5a7c-41ae-b27c-6c66f58372db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "nn1f_X = np.concatenate([train_df['signal'].values[1000000: 1500000], train_df['signal'].values[3000000: 3500000]])\n",
        "nn1f_y = np.concatenate([train_df['open_channels'].values[1000000: 1500000], train_df['open_channels'].values[3000000: 3500000]])\n",
        "\n",
        "X, y = resample.fit_sample(np.array(nn1f_X).reshape(-1, 1), np.array(nn1f_y).reshape(-1, 1))\n",
        "\n",
        "a = pd.DataFrame(X, columns=['signal'])\n",
        "a = a.to_numpy()\n",
        "X = a.reshape(X.shape[0], 1, 1, 1)\n",
        "\n",
        "b = pd.DataFrame(y, columns=['open_channels'])\n",
        "b = b.to_numpy()\n",
        "y = b.reshape(len(b), 1)\n",
        "from numpy import array\n",
        "y = to_categorical(array(y), num_classes=2)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=100)\n",
        "\n",
        "model1f.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=2, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "model1f.fit(x=X_train, y=y_train, initial_epoch=0, epochs=4, batch_size=256, callbacks=[lrate], verbose=1, shuffle=False, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "5244/5244 [==============================] - 79s 15ms/step - loss: 0.0156 - accuracy: 0.9950 - precision_25: 0.9950 - recall_25: 0.9950 - f1_score: 0.9950 - val_loss: 0.0096 - val_accuracy: 0.9966 - val_precision_25: 0.9966 - val_recall_25: 0.9966 - val_f1_score: 0.9966 - lr: 0.1000\n",
            "Epoch 2/4\n",
            "5244/5244 [==============================] - 79s 15ms/step - loss: 0.0118 - accuracy: 0.9959 - precision_25: 0.9959 - recall_25: 0.9959 - f1_score: 0.9959 - val_loss: 0.0095 - val_accuracy: 0.9966 - val_precision_25: 0.9966 - val_recall_25: 0.9966 - val_f1_score: 0.9966 - lr: 0.1000\n",
            "Epoch 3/4\n",
            "5244/5244 [==============================] - 77s 15ms/step - loss: 0.0107 - accuracy: 0.9963 - precision_25: 0.9963 - recall_25: 0.9963 - f1_score: 0.9963 - val_loss: 0.0095 - val_accuracy: 0.9967 - val_precision_25: 0.9967 - val_recall_25: 0.9967 - val_f1_score: 0.9967 - lr: 1.0000e-04\n",
            "Epoch 4/4\n",
            "5244/5244 [==============================] - 78s 15ms/step - loss: 0.0107 - accuracy: 0.9963 - precision_25: 0.9963 - recall_25: 0.9963 - f1_score: 0.9963 - val_loss: 0.0095 - val_accuracy: 0.9967 - val_precision_25: 0.9967 - val_recall_25: 0.9967 - val_f1_score: 0.9967 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c4e290320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ffjjSKT6JB",
        "colab_type": "code",
        "outputId": "d2df8da7-e041-4553-bb6c-f75f3b89c644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "nn3_X = np.concatenate([train_df['signal'].values[1500000: 2000000], train_df['signal'].values[3500000: 4000000]])\n",
        "nn3_y = np.concatenate([train_df['open_channels'].values[1500000: 2000000], train_df['open_channels'].values[3500000: 4000000]])\n",
        "\n",
        "X, y = resample.fit_sample(np.array(nn3_X).reshape(-1, 1), np.array(nn3_y).reshape(-1, 1))\n",
        "\n",
        "a = pd.DataFrame(X, columns=['signal'])\n",
        "a = a.to_numpy()\n",
        "X = a.reshape(X.shape[0], 1, 1, 1)\n",
        "\n",
        "b = pd.DataFrame(y, columns=['open_channels'])\n",
        "b = b.to_numpy()\n",
        "y = b.reshape(len(b), 1)\n",
        "from numpy import array\n",
        "y = to_categorical(array(y), num_classes=4)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=100)\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=4, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "model3.fit(x=X_train, y=y_train, initial_epoch=0, epochs=4, batch_size=256, callbacks=[lrate], verbose=1, shuffle=False, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "5731/5731 [==============================] - 86s 15ms/step - loss: 0.0384 - accuracy: 0.9892 - precision_26: 0.9894 - recall_26: 0.9890 - f1_score: 0.9893 - val_loss: 0.0266 - val_accuracy: 0.9926 - val_precision_26: 0.9927 - val_recall_26: 0.9926 - val_f1_score: 0.9927 - lr: 0.1000\n",
            "Epoch 2/4\n",
            "5731/5731 [==============================] - 86s 15ms/step - loss: 0.0321 - accuracy: 0.9908 - precision_26: 0.9910 - recall_26: 0.9907 - f1_score: 0.9909 - val_loss: 0.0264 - val_accuracy: 0.9926 - val_precision_26: 0.9927 - val_recall_26: 0.9925 - val_f1_score: 0.9926 - lr: 0.1000\n",
            "Epoch 3/4\n",
            "5731/5731 [==============================] - 85s 15ms/step - loss: 0.0331 - accuracy: 0.9904 - precision_26: 0.9906 - recall_26: 0.9902 - f1_score: 0.9905 - val_loss: 0.0260 - val_accuracy: 0.9927 - val_precision_26: 0.9928 - val_recall_26: 0.9926 - val_f1_score: 0.9927 - lr: 1.0000e-04\n",
            "Epoch 4/4\n",
            "5731/5731 [==============================] - 85s 15ms/step - loss: 0.0300 - accuracy: 0.9915 - precision_26: 0.9916 - recall_26: 0.9913 - f1_score: 0.9916 - val_loss: 0.0257 - val_accuracy: 0.9928 - val_precision_26: 0.9929 - val_recall_26: 0.9927 - val_f1_score: 0.9929 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c3c7e79e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7kfipGFUakN",
        "colab_type": "code",
        "outputId": "a3175ecd-e3e9-4e61-e07b-1ded15bdda62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "nn5_X = np.concatenate([train_df['signal'].values[2500000: 3000000], train_df['signal'].values[4000000: 4500000]])\n",
        "nn5_y = np.concatenate([train_df['open_channels'].values[2500000: 3000000], train_df['open_channels'].values[4000000: 4500000]])\n",
        "\n",
        "X, y = resample.fit_sample(np.array(nn5_X).reshape(-1, 1), np.array(nn5_y).reshape(-1, 1))\n",
        "\n",
        "a = pd.DataFrame(X, columns=['signal'])\n",
        "a = a.to_numpy()\n",
        "X = a.reshape(X.shape[0], 1, 1, 1)\n",
        "\n",
        "b = pd.DataFrame(y, columns=['open_channels'])\n",
        "b = b.to_numpy()\n",
        "y = b.reshape(len(b), 1)\n",
        "from numpy import array\n",
        "y = to_categorical(array(y), num_classes=6)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=100)\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=6, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "model5.fit(x=X_train, y=y_train, initial_epoch=0, epochs=4, batch_size=256, callbacks=[lrate], verbose=1, shuffle=False, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "7430/7430 [==============================] - 111s 15ms/step - loss: 0.0318 - accuracy: 0.9890 - precision_27: 0.9891 - recall_27: 0.9890 - f1_score: 0.9890 - val_loss: 0.0294 - val_accuracy: 0.9898 - val_precision_27: 0.9898 - val_recall_27: 0.9898 - val_f1_score: 0.9898 - lr: 0.1000\n",
            "Epoch 2/4\n",
            "7430/7430 [==============================] - 109s 15ms/step - loss: 0.0252 - accuracy: 0.9914 - precision_27: 0.9914 - recall_27: 0.9913 - f1_score: 0.9914 - val_loss: 0.0234 - val_accuracy: 0.9920 - val_precision_27: 0.9921 - val_recall_27: 0.9920 - val_f1_score: 0.9921 - lr: 0.1000\n",
            "Epoch 3/4\n",
            "7430/7430 [==============================] - 112s 15ms/step - loss: 0.0251 - accuracy: 0.9913 - precision_27: 0.9914 - recall_27: 0.9913 - f1_score: 0.9914 - val_loss: 0.0198 - val_accuracy: 0.9932 - val_precision_27: 0.9932 - val_recall_27: 0.9932 - val_f1_score: 0.9933 - lr: 1.0000e-04\n",
            "Epoch 4/4\n",
            "7430/7430 [==============================] - 112s 15ms/step - loss: 0.0226 - accuracy: 0.9924 - precision_27: 0.9924 - recall_27: 0.9924 - f1_score: 0.9924 - val_loss: 0.0196 - val_accuracy: 0.9932 - val_precision_27: 0.9932 - val_recall_27: 0.9931 - val_f1_score: 0.9932 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c3a7c9a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9KmF-V8U8o-",
        "colab_type": "code",
        "outputId": "a663fee3-2691-4620-bdb0-3a6a07beebd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "nn10_y = np.concatenate([train_df['open_channels'].values[2000000: 2500000], train_df['open_channels'].values[4500000: 5000000]])\n",
        "nn10_y = pd.Series(nn10_y)\n",
        "index =np.array([nn10_y[nn10_y == 0].index[0], nn10_y[nn10_y == 0].index[1]])\n",
        "\n",
        "nn10_X = np.concatenate([train_df['signal'].values[2000000: 2500000], train_df['signal'].values[4500000: 5000000]])\n",
        "nn10_y = np.concatenate([train_df['open_channels'].values[2000000: 2500000], train_df['open_channels'].values[4500000: 5000000]])\n",
        "nn10_X = np.delete(nn10_X, index)\n",
        "nn10_y = np.delete(nn10_y, index)\n",
        "resample = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='not majority'), random_state=100)\n",
        "X, y = resample.fit_sample(np.array(nn10_X).reshape(-1, 1), np.array(nn10_y).reshape(-1, 1))\n",
        "\n",
        "a = pd.DataFrame(X, columns=['signal'])\n",
        "a = a.to_numpy()\n",
        "X = a.reshape(X.shape[0], 1, 1, 1)\n",
        "\n",
        "b = pd.DataFrame(y, columns=['open_channels'])\n",
        "b = b.to_numpy()\n",
        "y = b.reshape(len(b), 1)\n",
        "from numpy import array\n",
        "y = to_categorical(array(y), num_classes=11)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=100)\n",
        "\n",
        "# model10.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=11, average='macro')])\n",
        "# lrate = LearningRateScheduler(step_decay)\n",
        "# model10.fit(x=X_train, y=y_train, initial_epoch=0, epochs=4, batch_size=256, callbacks=[lrate], verbose=1, shuffle=False, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaUGati_jcDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y.shape\n",
        "# y = to_categorical(array(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHfdGc4-bdPK",
        "colab_type": "code",
        "outputId": "d7d7ca0d-094c-4273-80f0-4e8ed297063d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=100)\n",
        "\n",
        "# Model 10\n",
        "maxchannels = 10\n",
        "model10 = Sequential()\n",
        "timestep = 1\n",
        "input_dim = 1\n",
        "model10.add(TimeDistributed(Conv1D(filters=128, kernel_size=1, activation='relu'), input_shape=(None, 1, 1)))\n",
        "model10.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
        "model10.add(TimeDistributed(Flatten()))\n",
        "model10.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model10.add(BatchNormalization())\n",
        "model10.add(Dropout(0.2))\n",
        "model10.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "model10.add(BatchNormalization())\n",
        "model10.add(Dropout(0.2))\n",
        "model10.add(LSTM(256, activation='relu'))\n",
        "model10.add(BatchNormalization())\n",
        "model10.add(Dropout(0.2))\n",
        "model10.add(Dense(maxchannels+1))\n",
        "model10.add(Activation('softmax'))\n",
        "model10.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False), metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=11, average='macro')])\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "model10.fit(x=X_train, y=y_train, initial_epoch=0, epochs=4, batch_size=256, callbacks=[lrate], verbose=1, shuffle=False, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/4\n",
            "7048/7048 [==============================] - 107s 15ms/step - loss: 0.1454 - accuracy: 0.9446 - precision_28: 0.9449 - recall_28: 0.9443 - f1_score: 0.8585 - val_loss: 0.1293 - val_accuracy: 0.9459 - val_precision_28: 0.9461 - val_recall_28: 0.9457 - val_f1_score: 0.8599 - lr: 0.1000\n",
            "Epoch 2/4\n",
            "7048/7048 [==============================] - 106s 15ms/step - loss: 0.1199 - accuracy: 0.9536 - precision_28: 0.9538 - recall_28: 0.9535 - f1_score: 0.8670 - val_loss: 0.1083 - val_accuracy: 0.9573 - val_precision_28: 0.9574 - val_recall_28: 0.9573 - val_f1_score: 0.8701 - lr: 0.1000\n",
            "Epoch 3/4\n",
            "7048/7048 [==============================] - 107s 15ms/step - loss: 0.1658 - accuracy: 0.9399 - precision_28: 0.9401 - recall_28: 0.9396 - f1_score: 0.8540 - val_loss: 0.0920 - val_accuracy: 0.9648 - val_precision_28: 0.9648 - val_recall_28: 0.9647 - val_f1_score: 0.8771 - lr: 1.0000e-04\n",
            "Epoch 4/4\n",
            "7048/7048 [==============================] - 104s 15ms/step - loss: 0.1141 - accuracy: 0.9562 - precision_28: 0.9563 - recall_28: 0.9560 - f1_score: 0.8694 - val_loss: 0.0915 - val_accuracy: 0.9653 - val_precision_28: 0.9653 - val_recall_28: 0.9652 - val_f1_score: 0.8776 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c383fef60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Uuj4KhnDD1",
        "colab_type": "code",
        "outputId": "1d67211f-b374-491f-854e-8b5d7f4906ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNt9HOQfWJFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicitons\n",
        "sub = pd.read_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/sample_submission.csv')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/test_clean.csv')\n",
        "test_df = np.array(test_df['signal']).reshape(test_df['signal'].shape[0], 1, 1, 1)\n",
        "a = 0 # SUBSAMPLE A, Model 1s\n",
        "pred_y = model1s.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 1 # SUBSAMPLE B, Model 3\n",
        "pred_y = model3.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 2 # SUBSAMPLE C, Model 5\n",
        "pred_y = model5.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 3 # SUBSAMPLE D, Model 1s\n",
        "pred_y = model1s.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 4 # SUBSAMPLE E, Model 1f\n",
        "pred_y = model1f.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 5 # SUBSAMPLE F, Model 10\n",
        "pred_y = model10.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 6 # SUBSAMPLE G, Model 5\n",
        "pred_y = model5.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 7 # SUBSAMPLE H, Model 10\n",
        "pred_y = model10.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 8 # SUBSAMPLE I, Model 1s\n",
        "pred_y = model1s.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        "a = 9 # SUBSAMPLE J, Model 3\n",
        "pred_y = model3.predict(test_df[100000*a:100000*(a+1)], batch_size=256)\n",
        "decoded_datum = np.empty((100000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[100000*a:100000*(a+1),1] = decoded_datum.astype(int)\n",
        "\n",
        " # BATCHES 3 AND 4, Model 1s\n",
        "pred_y = model1s.predict(test_df[1000000:2000000], batch_size=256)\n",
        "decoded_datum = np.empty((1000000, 1))\n",
        "\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)\n",
        "\n",
        "for i in range(pred_y.shape[0]):\n",
        "    datum = pred_y[i]\n",
        "    decoded_datum[i] = decode(datum)\n",
        "sub.iloc[1000000:2000000,1] = decoded_datum.astype(int)\n",
        "\n",
        "sub.to_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/submission-Neural-Network.csv',index=False,float_format='%.4f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecu68Xo1oOtP",
        "colab_type": "code",
        "outputId": "e55f3658-6b48-46e6-bbc1-d676dc3f0d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ans = pd.read_csv('/content/drive/My Drive/Ion_Channel/Kaggle_dataset/submission-Neural-Network.csv')\n",
        "ans['open_channels'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.377289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}